# Конфигурация системы

## Серверы и порты

### Сервер моделей
**Хост:** 139.59.241.176
**Сервисы:**
- **llama-server (Mistral API):** Порт 8080
  - Запускается через systemd: `llama-server.service`
  - Путь к моделям: `/opt/models/mistral/`
  - Используемая модель: `Mistral-7B-Instruct-v0.3.Q4_K_M.gguf`
  - Команда запуска: `./llama-server -m /opt/models/mistral/Mistral-7B-Instruct-v0.3.Q4_K_M.gguf --port 8080 --host 0.0.0.0 --ctx-size 4096 --batch-size 512 --parallel 4`

- **API Gateway:** Порт 8000
  - Используется для маршрутизации запросов
  - Предоставляет единую точку доступа к сервисам

### Локальный сервер разработки
**Хост:** localhost
**Сервисы:**
- **Оркестратор API:** Порт 8002
  - Команда запуска: `python run_api_server.py`
  - Переменные окружения:
    - `API_SERVER_PORT=8002`
    - `API_SERVER_HOST=0.0.0.0`

## Адреса API и эндпоинты

### Mistral API
**Базовый URL:** `http://139.59.241.176:8080`
**Эндпоинты:**
- `/v1/chat/completions` - Генерация текста (POST)
- `/v1/models` - Получение списка моделей (GET)
- `/health` - Проверка состояния сервера (GET)

### Формат запроса для генерации текста
```json
{
  "model": "TheBloke/Mistral-7B-Instruct-v0.3-GPTQ",
  "messages": [
    {"role": "user", "content": "Привет, как дела?"}
  ],
  "temperature": 0.7,
  "max_tokens": 1000,
  "top_p": 0.9
}
```

## Используемые модели

| Название модели | Описание | Параметры по умолчанию | Максимальный контекст |
|-----------------|----------|------------------------|------------------------|
| TheBloke/Mistral-7B-Instruct-v0.3-GPTQ | Основная модель для генерации текста | temperature: 0.7, top_p: 0.9 | 8000 токенов |

## Интеграция с Telegram

**Бот:** Запускается через скрипт `run_telegram_bot.py`
**Логи:** `logs/telegram_bot.log`
**Настройки API:**
- URL Mistral API: `http://139.59.241.176:8080`
- Таймаут запросов: 180 секунд
- Модель по умолчанию: `"TheBloke/Mistral-7B-Instruct-v0.3-GPTQ"`

## Мониторинг API

**Скрипт:** `src/utils/monitoring_script.py` 
**Логи:** `logs/api_monitoring.log`
**Настройки:**
- URL API: `http://139.59.241.176:8080`
- Интервал проверки: 60 секунд
- Команда перезапуска: `ssh root@139.59.241.176 "systemctl restart llama-server.service"`

## Изменения конфигурации

| Дата | Изменение | Причина |
|------|-----------|---------|
| 14.03.2025 | Изменен порт для Mistral API с 8000 на 8080 | Обнаружено несоответствие между настройками клиента и фактическим портом сервера | 